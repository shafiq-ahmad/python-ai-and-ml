{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': [20, 30, 40, 50],\n",
       " 'height': [160, 170, 180, 190],\n",
       " 'weight': [60, 70, 80, 90]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = {\n",
    "    'age': [20, 30, 40, 50],\n",
    "    'height': [160, 170, 180, 190],\n",
    "    'weight': [60, 70, 80, 90]\n",
    "}\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>170</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>180</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>190</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height  weight\n",
       "0   20     160      60\n",
       "1   30     170      70\n",
       "2   40     180      80\n",
       "3   50     190      90"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covert data to dataframe\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>-1.341641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.447214</td>\n",
       "      <td>-0.447214</td>\n",
       "      <td>-0.447214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>1.341641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0 -1.341641 -1.341641 -1.341641\n",
       "1 -0.447214 -0.447214 -0.447214\n",
       "2  0.447214  0.447214  0.447214\n",
       "3  1.341641  1.341641  1.341641"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the scalar / standardscaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit and transform\n",
    "scaled_df = scaler.fit_transform(df)\n",
    "scaled_df\n",
    "\n",
    "# covert to dataframe\n",
    "df_standard = pd.DataFrame(scaled_df)\n",
    "df_standard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  0.000000  0.000000  0.000000\n",
       "1  0.333333  0.333333  0.333333\n",
       "2  0.666667  0.666667  0.666667\n",
       "3  1.000000  1.000000  1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the scalar / minmaxscaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit and transform\n",
    "scaled_df = scaler.fit_transform(df)\n",
    "scaled_df\n",
    "\n",
    "# covert to dataframe\n",
    "df_minmax = pd.DataFrame(scaled_df)\n",
    "df_minmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max Abs scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2\n",
       "0  0.4  0.842105  0.666667\n",
       "1  0.6  0.894737  0.777778\n",
       "2  0.8  0.947368  0.888889\n",
       "3  1.0  1.000000  1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the scalar \n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "# fit and transform\n",
    "scaled_df = scaler.fit_transform(df)\n",
    "scaled_df\n",
    "\n",
    "# covert to dataframe\n",
    "df_maxabsscaler = pd.DataFrame(scaled_df)\n",
    "df_maxabsscaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Transfrmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.591749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.511862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.846446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.574402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.102097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     values\n",
       "0  1.591749\n",
       "1  2.511862\n",
       "2  1.846446\n",
       "3  1.574402\n",
       "4  1.102097"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate non-normal data (exponentially distributed)\n",
    "np.random.seed(0)\n",
    "df = np.random.exponential(size=1000, scale=2)\n",
    "df = pd.DataFrame(df, columns=['values'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='values', ylabel='Count'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1.59174902e+00 2.51186153e+00 1.84644629e+00 1.57440230e+00\n 1.10209698e+00 2.07631859e+00 1.15103840e+00 4.44704883e+00\n 6.62982436e+00 9.67204202e-01 3.13779228e+00 1.50534822e+00\n 1.67886569e+00 5.19650831e+00 1.47370710e-01 1.82322058e-01\n 4.08511734e-02 3.57497536e+00 3.01156846e+00 4.08062856e+00\n 7.69044368e+00 3.21047912e+00 1.23785892e+00 3.03307195e+00\n 2.51748824e-01 2.04286377e+00 3.09459365e-01 5.78884090e+00\n 1.47565456e+00 1.07113144e+00 6.14560706e-01 2.97650968e+00\n 1.21816483e+00 1.68066941e+00 3.79371433e-02 1.92276186e+00\n 1.89399336e+00 1.91909595e+00 5.75583016e+00 2.29027792e+00\n 8.91036985e-01 1.14906482e+00 2.39221560e+00 1.24230592e-01\n 2.19782496e+00 2.22119487e+00 4.72413411e-01 2.76057375e-01\n 7.57923932e-01 9.04204113e-01 1.68885556e+00 1.15464862e+00\n 8.90899476e+00 2.15270225e-01 4.68603031e-01 3.51827107e-01\n 2.11748545e+00 5.84161070e-01 1.25588316e+00 5.60554027e-01\n 3.46254906e-01 2.33910824e-01 2.13614438e+00 2.97424543e-01\n 4.37761205e-01 9.20027931e-01 3.44066330e+00 2.04289773e-01\n 3.63963785e+00 2.02069566e-01 7.49806290e+00 1.26467321e+00\n 7.52385434e+00 1.85695700e+00 2.68849053e+00 7.99526050e-02\n 6.64820491e-01 2.56113523e-01 7.02352174e-01 2.52777283e-01\n 7.65401916e-01 1.06976877e+00 1.32594793e-01 2.35837905e+00\n 1.67219509e+00 6.16829680e-01 1.48151790e+00 1.97300627e-01\n 1.71579128e+00 5.29851185e+00 7.67120421e-01 2.20169184e+00\n 2.82661428e-01 2.51986766e+00 6.83308340e-01 4.04700874e-01\n 1.76625809e+00 4.06249087e-02 3.53148216e+00 9.41306914e-03\n 2.26526827e+00 6.29443334e-01 2.65751576e+00 6.55028637e+00\n 5.72041955e-01 1.71678593e+00 1.79318177e+00 1.69844164e+00\n 5.04839991e-01 6.10456341e+00 1.18524806e+00 3.74691984e+00\n 2.40447712e+00 7.06040264e-01 3.36184441e+00 1.01003750e+00\n 4.25899873e+00 1.74107164e+00 4.26966094e+00 2.35876586e+00\n 2.58381853e+00 1.39159892e+00 6.25093649e+00 2.06559404e+00\n 1.10279200e+00 1.86480575e+00 3.87595580e-02 7.17854433e-01\n 2.15864039e+00 6.85199242e-01 1.92475012e+00 1.11992215e+00\n 2.91147947e-01 7.08448259e-01 1.68777694e+00 1.78745815e+00\n 1.70815944e+00 2.11801880e+00 2.11169919e+00 1.12922101e+00\n 4.53726794e+00 9.16345763e-01 1.14492312e+00 4.44982926e+00\n 3.28179513e+00 2.43403898e+00 2.11225289e-01 5.03856428e+00\n 2.50521506e+00 1.35307875e+01 3.23740173e-01 4.05181759e+00\n 3.54651158e-01 1.91193283e+00 2.64367420e-01 3.76785780e+00\n 3.29343819e+00 1.68376190e+00 1.04574006e+00 1.43350780e-01\n 2.39087714e+00 1.20859815e+00 2.56066837e+00 4.02554547e+00\n 7.41992060e+00 3.87315447e+00 2.35664692e-02 8.92505658e-01\n 2.61859673e+00 3.76589950e-01 1.47226221e+00 1.11740111e-01\n 4.46278415e-01 3.73909415e-02 3.15682545e+00 5.07011424e-01\n 8.47314209e-01 5.26443775e+00 2.43759362e+00 6.47136209e-02\n 3.59914683e-01 1.94296429e+00 1.72184729e+00 5.43336158e-01\n 5.44269640e+00 1.90365943e+00 1.53415933e+00 1.78275715e+00\n 2.61957077e+00 7.47772992e-01 1.01573023e+00 4.71049134e-01\n 4.12064098e-01 5.77815124e+00 2.69069485e+00 1.34848917e+00\n 5.16025525e-01 5.87015301e-01 1.19561921e-01 1.13979512e+00\n 7.47339604e-01 2.38371623e+00 9.48832587e-01 3.95935471e-01\n 4.99767058e-02 1.39235344e-01 2.27507700e+00 1.20916246e+00\n 1.53823961e+00 4.53968009e+00 9.27930534e+00 4.88982053e-01\n 2.17580886e+00 6.11209800e-01 4.17344264e-02 2.84076693e+00\n 7.71375406e-01 9.67276785e-01 1.77500384e+00 3.55628665e+00\n 1.98300856e+00 4.12164245e+00 6.39149314e-01 3.19943892e+00\n 4.10695540e-01 6.10636929e+00 2.32622659e+00 4.85436986e-01\n 5.88896040e+00 2.62501602e+00 5.85902910e-01 4.79847045e-01\n 1.46045534e+00 5.19954998e-02 4.65050028e-01 1.10567675e+00\n 9.37352958e-01 1.24565863e+00 6.50432030e-01 1.76757132e+00\n 3.98807847e+00 2.50065176e-01 1.45704767e+00 2.83284062e-01\n 2.52362536e+00 1.00855986e+00 1.66675650e+00 4.04917519e-01\n 3.12951533e-01 1.33908117e+00 8.78910790e-01 5.64127169e+00\n 2.89910956e+00 2.76192615e+00 4.68098393e+00 1.74217168e-01\n 1.60678352e+00 1.75643014e+00 6.53699254e+00 6.91039156e-01\n 5.51055881e-01 2.11374343e-01 3.31321854e-02 5.30511699e+00\n 2.21681953e+00 3.07565745e+00 6.61819767e-01 1.76576107e+00\n 1.32184022e-01 1.32961551e+00 7.58804796e+00 4.18311319e+00\n 8.25459721e-01 6.51784179e+00 5.27154228e-01 5.96440138e+00\n 5.67328038e+00 3.21091755e+00 1.99092729e+00 4.14752287e+00\n 6.93506609e-01 3.78020341e+00 1.92402385e+00 2.66504916e-02\n 8.53071643e-01 3.20668191e-01 8.01589963e+00 1.30159469e+00\n 1.37588695e+00 2.04037418e+00 9.19582645e-01 2.94450069e-01\n 3.45326674e+00 4.21066572e-01 1.43209064e+00 5.08022770e-01\n 2.05936724e-01 3.96378073e+00 7.21788192e+00 6.47992612e+00\n 4.74077519e+00 2.97485948e+00 8.10365752e-01 1.69158978e-01\n 1.04593532e+00 5.28540930e-01 2.84251027e-01 1.09814754e-01\n 2.58629569e+00 2.29865075e-02 2.94440831e+00 3.17866368e-01\n 1.65724537e-01 1.87749097e-01 2.22977487e+00 5.63048037e-01\n 1.09131545e+00 1.63003668e+00 3.94011517e+00 2.59689126e+00\n 6.30320062e-01 2.81935777e-01 1.13933072e-01 7.17922638e-01\n 6.07943122e-01 1.21812892e+00 2.29948279e+00 2.37899250e+00\n 6.66806671e-01 9.55835990e-01 3.99711073e-01 3.10749098e+00\n 1.17055805e-01 2.38802674e+00 3.01643046e+00 3.00482562e+00\n 6.00650157e-01 9.36212901e-01 1.77152128e+00 6.37167711e-01\n 9.26780052e-01 4.38936328e-01 1.23183859e+00 9.12761072e-02\n 3.21683571e+00 1.60157718e-01 1.46309068e+00 7.32902581e-01\n 1.72333498e+00 6.40961751e+00 2.07449021e+00 7.20056586e-02\n 1.12565040e+00 1.42676856e+00 1.53650666e+00 2.28759075e+00\n 6.50341750e-01 2.75906459e-01 9.97384650e-01 6.26565879e+00\n 4.14370362e-01 4.68647993e+00 1.56967402e+00 1.22096569e+00\n 4.27484330e+00 1.22720844e+00 2.57592395e+00 1.01840496e+00\n 4.68773924e+00 2.34252739e+00 2.40542756e+00 7.94161912e-01\n 2.82756663e+00 2.02153832e+00 5.48927043e-01 3.49990097e-01\n 3.18311224e+00 6.39650996e+00 1.22549090e+00 1.78800282e+00\n 3.89995383e+00 1.22211512e+00 6.06788523e+00 1.71487023e+00\n 3.43813863e+00 4.79035973e+00 3.38046985e+00 3.47313125e-01\n 1.98255901e+00 1.01643891e+00 1.29531392e-01 1.10340723e+00\n 5.98656768e-01 3.78145835e+00 6.77437109e-02 6.38752377e+00\n 8.78153968e-01 8.82309623e-01 3.29265637e-02 4.09704536e-01\n 1.02585400e+00 5.29837663e+00 2.09865504e-01 5.81183921e+00\n 4.07258834e+00 1.21086756e+00 7.91131186e-01 5.29869868e-01\n 1.90624508e+00 6.72678470e-02 3.14582421e-02 1.12001676e+00\n 1.41003892e-01 5.80546823e-01 4.99901642e-01 5.83892151e-01\n 2.80951426e-01 2.42184895e-02 2.45430024e-01 1.92718537e+00\n 7.31912391e+00 9.28055905e+00 1.05206160e+00 3.55753522e-01\n 2.03643517e+00 1.34788690e+00 9.09564818e+00 1.35068316e-01\n 3.05787774e+00 6.80474423e-01 5.52610391e-01 2.17240663e+00\n 5.64893428e-01 2.19238514e+00 1.45675516e+00 1.10360425e+00\n 1.61795938e+00 6.76692238e-01 2.45226442e+00 1.07179759e+00\n 8.94279809e-01 3.52817477e+00 5.17965218e+00 9.41985419e-02\n 5.29564552e-01 8.57015227e-01 3.37443656e+00 8.46603121e+00\n 6.94571148e+00 4.70666961e+00 7.03534769e-01 9.65944031e+00\n 5.73818185e-01 2.23889074e-01 6.02993665e+00 5.31633098e-01\n 2.34087146e+00 1.20256753e-01 2.62392614e+00 4.26940476e+00\n 6.36109084e-01 9.53031643e-01 9.37756312e-01 2.76291820e+00\n 5.43111585e-01 3.77129447e-01 1.19309984e+00 7.26157689e-01\n 3.65505255e+00 5.42939939e-01 1.39587510e+00 5.71485059e+00\n 2.01023131e+00 4.03916901e+00 5.63382332e+00 2.77871700e+00\n 2.40511468e+00 6.88188782e+00 1.03702594e+01 1.20230930e+00\n 1.47012752e-01 6.92866656e-01 3.30586031e-01 1.08080541e+00\n 2.81490307e-01 1.85327719e+00 9.65150432e-01 4.51495357e+00\n 6.87124674e+00 1.58321821e+00 6.42680604e-01 1.79410603e+00\n 4.54142025e+00 1.04422262e+00 1.60627357e+00 6.33954754e-01\n 1.21556954e+00 1.02737120e+00 5.71137854e-01 1.40989864e+00\n 7.43231511e-01 9.33728688e-01 1.48875650e+00 2.77735458e+00\n 8.11452682e-01 5.15822632e+00 3.96562514e+00 9.98312160e-02\n 5.85101207e-01 1.18167046e+00 2.21031761e-01 8.56882056e-01\n 2.69489763e+00 2.28208666e+00 1.94775722e+00 2.47939619e+00\n 4.58634355e-01 8.36183322e-01 2.25552089e+00 4.22781362e+00\n 1.56911339e+00 6.64521258e-01 6.14035419e-02 2.47807302e+00\n 1.58306948e-02 9.32594038e-01 1.51233250e+00 5.10495294e+00\n 1.87510777e-01 1.04155773e+00 4.92272908e-02 8.38958653e-01\n 1.94694507e+00 6.54420776e-01 4.70811728e-01 2.45925128e-01\n 1.72142940e+00 2.37665832e+00 2.22922202e+00 5.94641654e+00\n 5.41374835e-03 2.08368894e+00 1.83454361e+00 1.77705743e+00\n 6.58129796e+00 3.40312429e-02 2.38463156e+00 3.36056481e+00\n 1.42591298e+00 8.12825723e-01 3.12931310e+00 2.04603565e-01\n 1.16692037e+00 1.46773992e+00 2.36805548e+00 1.90568971e-01\n 5.16918502e-01 1.05628799e+00 1.95258405e+00 4.36004090e+00\n 1.92899951e+00 2.86497411e-01 7.88291731e+00 4.10810493e+00\n 1.39720712e+00 5.11103548e+00 1.55907006e+00 5.13586537e+00\n 3.54270662e+00 6.90201999e+00 5.04603492e+00 7.33981306e-02\n 3.84191144e-01 9.85757530e-01 6.07906311e+00 7.13432517e-01\n 3.49820522e-01 4.34846584e+00 1.18260557e+00 4.76923076e+00\n 3.49255579e-01 2.16420375e+00 1.16057919e+00 1.59140305e-01\n 2.38450448e+00 5.68439495e-01 8.08431548e-02 1.23632297e-01\n 1.26046885e-01 4.76613654e+00 2.69325456e+00 4.56678800e+00\n 2.23303718e+00 1.50553931e+00 7.26094305e-01 1.23918193e+01\n 8.99426740e-01 1.27220691e+00 9.50418872e-01 7.77728977e+00\n 3.83915800e-01 7.94958166e-01 2.28104892e+00 1.30587198e-01\n 1.86916082e+00 1.29882145e+00 6.68150159e-01 5.44702468e-01\n 1.44520448e+00 9.17502607e-01 1.21952434e+00 8.23401162e-01\n 7.04630252e+00 2.86446545e-01 2.03631286e-01 8.41335354e-01\n 1.78821179e+00 2.15278090e+00 1.01252791e+00 1.44669540e+01\n 8.67398934e-01 2.55600430e+00 2.02991791e+00 3.35386948e+00\n 7.47829715e+00 4.41080164e+00 2.89261512e+00 2.39630275e+00\n 8.17435293e-01 3.19599561e-01 1.29367203e-01 5.53884448e-01\n 1.13225910e+00 1.47627350e+00 2.96634682e+00 6.37576829e+00\n 2.49586178e-01 2.26346669e-01 1.78170764e+00 2.73610806e+00\n 3.76972918e+00 5.49250377e+00 8.19986939e+00 1.02099033e+00\n 9.57153131e-01 3.19888439e-01 2.30994906e+00 2.13866215e+00\n 3.96191058e+00 2.04636950e-01 1.37742170e+00 1.74015983e+00\n 5.52975368e-01 3.70312115e-01 3.92624661e+00 1.20636047e-01\n 1.27210095e+00 2.46220905e-01 1.22150836e+00 7.82028219e+00\n 1.10227589e+00 3.89156916e+00 2.49575039e-01 6.32854782e-01\n 1.03433384e+00 1.02102515e+00 2.22572759e+00 8.45379592e-01\n 2.50189731e+00 2.03879036e+00 1.01885702e+00 1.13042328e+00\n 1.90657189e+00 1.45232119e-01 3.45651878e+00 2.11928991e+00\n 2.59175565e+00 1.53972387e+00 2.34140080e-01 1.03850746e+00\n 1.03964388e+00 7.74394934e-01 6.08159947e-02 2.67313683e+00\n 2.32583327e-01 1.86437348e+00 2.42951144e+00 2.01454536e+00\n 6.39531761e+00 2.18063727e-01 4.03732755e+00 5.92494926e-02\n 1.53107817e+00 1.03584690e+00 1.48544752e+00 9.08575158e-01\n 4.22842343e-01 3.86162100e-02 1.46024406e+00 3.70017845e+00\n 9.34306449e-01 5.04279355e-01 1.67920082e-01 1.78342156e-01\n 5.00506559e-01 2.10752278e-01 6.15877585e-01 1.36877754e-01\n 1.35711752e-01 3.87972347e+00 3.53761396e-01 1.64051801e+00\n 2.96962816e+00 1.21911839e+00 3.32980380e-01 4.45277713e-01\n 1.13473624e+00 1.50254474e+00 8.59844395e-01 3.04175181e+00\n 2.78077866e+00 5.24040305e+00 5.87598875e-02 4.52080085e+00\n 9.97032684e-01 4.21358429e+00 2.34743545e+00 8.73999963e+00\n 2.84826206e+00 9.06826825e-01 1.39055158e+00 9.44457503e-01\n 9.07982898e-01 6.04656274e-01 1.37024015e+00 2.28977290e+00\n 6.49633611e-01 1.48627133e+00 2.49721711e-01 3.48338444e-01\n 9.58744010e-02 7.06248294e+00 7.73564380e-03 3.93441380e-01\n 1.89797268e+00 1.69742825e-01 4.27238789e+00 2.54322003e+00\n 6.78586157e+00 1.41707216e+00 7.14503601e-01 1.59479695e+00\n 5.34204987e+00 1.47111352e+00 6.21784123e-01 4.19763676e+00\n 9.30171479e-01 2.76861542e-03 5.69200379e-01 7.66136137e-01\n 3.91483679e+00 1.22683612e+00 1.17608763e+00 8.19254314e-01\n 4.25186118e+00 5.80181813e+00 9.62939600e+00 9.45587089e-01\n 6.77148164e+00 3.13927675e+00 2.25210560e+00 5.61782311e-01\n 4.87859340e-01 3.63158444e-01 5.12158787e+00 6.96497269e-01\n 1.20695757e+00 1.36227056e+00 3.01170230e+00 3.71881314e+00\n 2.99490432e-01 1.11340533e+00 3.70117124e+00 3.40786321e+00\n 2.16092145e-01 3.40114185e-01 7.25382272e-01 1.56699599e-01\n 1.10559866e+00 2.27721313e-01 1.67966701e+00 5.66203662e-01\n 1.81482584e+00 2.50051095e-01 7.44974860e+00 5.39306963e+00\n 9.94492940e-01 5.54615067e-01 5.76426328e-01 1.32094777e+00\n 8.16289931e-02 2.04166487e+00 1.04952089e+00 9.47723155e-01\n 3.31478905e+00 2.46910775e+00 6.17279440e+00 8.67532386e-01\n 4.55661957e+00 2.93906662e+00 8.84542391e-01 1.94395277e+00\n 6.80956381e-01 4.14930473e+00 2.38529730e-01 4.77617122e-01\n 4.04313868e-01 1.03176344e+00 2.73481144e+00 1.49692848e+00\n 1.33759735e+00 1.09222798e-03 1.10816827e+00 1.31326360e-01\n 4.67027402e-01 5.38811528e+00 4.85157913e-01 3.90861758e+00\n 3.24802087e+00 3.46675037e-01 1.86134713e+00 2.45831583e-01\n 2.60308423e+00 2.02925350e+00 3.34197314e+00 1.30548722e+00\n 4.92698917e+00 1.01216420e-01 6.93134018e-01 2.51090134e+00\n 1.08294500e+00 3.79783528e-01 2.26809446e-01 3.40024783e+00\n 1.28165215e+00 4.27895510e+00 2.64318021e+00 1.05433758e+00\n 9.35248171e-01 1.44984687e+00 4.39753068e+00 2.67332209e+00\n 1.03325732e-02 2.36937233e+00 5.03918022e+00 2.47889435e+00\n 3.89612207e-01 1.32143018e+00 3.02380840e-01 8.89436912e-01\n 5.53296018e+00 5.13584554e+00 6.64903844e-01 8.29913152e-01\n 1.83364609e+00 6.60436788e+00 3.19871207e-01 5.93894103e-01\n 4.13592460e+00 1.35412342e+00 4.58449922e+00 4.10405650e-01\n 1.52143322e+00 7.89850593e-01 7.61181785e-01 1.18434963e+00\n 1.13506516e+00 8.84300342e-01 4.92952041e+00 2.63162844e+00\n 2.60057825e+00 6.84736829e-01 1.72412327e+00 3.02080965e+00\n 3.17525860e+00 8.44806893e-01 2.94695556e+00 2.66280870e+00\n 3.05152307e-01 4.01901722e+00 1.16436210e+00 1.33266174e+00\n 1.18975252e+00 1.67794655e+00 1.94133147e+00 1.37902585e+00\n 4.03163503e+00 1.97629732e+00 1.02641675e+00 1.07807903e+00\n 3.33030948e+00 8.56010302e-01 4.75131090e-01 1.22438872e-01\n 4.17538050e+00 5.01544475e+00 2.55939903e-01 8.14354370e-01\n 3.85645975e-01 2.46366737e-01 4.60250682e+00 1.17117690e-01\n 7.87321175e+00 2.02849565e-01 3.98243133e+00 1.67175514e+00\n 9.17470672e-01 8.38141625e-01 2.83238698e+00 7.55427415e-01\n 2.14191010e+00 1.45682795e+00 1.32704334e+00 4.62854972e+00\n 1.61776739e+00 3.50732804e+00 2.58614388e+00 7.86405080e-02\n 2.96658038e+00 4.88913776e-01 4.66917649e+00 8.77453500e-02\n 8.10146473e-01 2.10127669e-01 1.29095955e+00 3.42984616e+00\n 7.08177609e-01 3.27238828e-01 8.01752414e-01 3.36272883e+00\n 3.02538904e-01 5.15890453e-01 1.42674015e-01 2.44637951e+00\n 1.00582484e+00 7.44563562e-01 2.53614384e+00 8.18878617e-01\n 2.60222532e+00 3.37695570e+00 4.90938970e-01 7.28541949e+00\n 3.54328830e-01 6.87350773e-01 3.96402649e-01 8.47784672e-01\n 1.30808713e+00 1.47702508e+00 3.84290790e+00 4.40453691e+00\n 4.97189046e-01 1.95045810e+00 2.36432388e-01 1.22856058e+00\n 7.78200112e-01 7.61059427e-01 1.31781711e+00 2.61739027e+00\n 1.43384435e-01 4.22679661e+00 2.65464593e+00 3.88381975e-01\n 5.59904551e+00 1.41170399e+00 1.71220615e+01 4.39447497e-01\n 1.53104094e+00 6.85679451e-01 7.25310028e-01 1.78839998e+00\n 5.09490243e+00 3.27221948e+00 2.57428422e+00 1.63820909e+00\n 5.10976153e+00 1.35597103e+00 4.14028468e+00 3.59131384e+00\n 4.81178052e-01 2.95003663e+00 2.44916640e-02 7.79664494e-01\n 5.21606323e-01 1.41393634e+00 2.67008616e+00 2.05564058e-01\n 1.44689199e+00 5.57457717e+00 5.19217162e-01 2.26108006e+00].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m pt_boxcox \u001b[38;5;241m=\u001b[39m PowerTransformer(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox-cox\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#pt_yeojohnson = PowerTransformer(method='yeo-johnson')\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# data must be postive for box-cox\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBox_cox\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpt_boxcox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#df['Yeo_johnson'] = pt_yeojohnson.fit_transform(df['values']) \u001b[39;00m\n\u001b[0;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\Shafiq\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Shafiq\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Shafiq\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:3142\u001b[0m, in \u001b[0;36mPowerTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   3124\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit `PowerTransformer` to `X`, then transform `X`.\u001b[39;00m\n\u001b[0;32m   3127\u001b[0m \n\u001b[0;32m   3128\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3140\u001b[0m \u001b[38;5;124;03m        Transformed data.\u001b[39;00m\n\u001b[0;32m   3141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Shafiq\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:3145\u001b[0m, in \u001b[0;36mPowerTransformer._fit\u001b[1;34m(self, X, y, force_transform)\u001b[0m\n\u001b[0;32m   3144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, force_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 3145\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_positive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   3147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_transform:  \u001b[38;5;66;03m# if call from fit()\u001b[39;00m\n\u001b[0;32m   3148\u001b[0m         X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# force copy so that fit does not change X inplace\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Shafiq\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:3383\u001b[0m, in \u001b[0;36mPowerTransformer._check_input\u001b[1;34m(self, X, in_fit, check_positive, check_shape)\u001b[0m\n\u001b[0;32m   3365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, in_fit, check_positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, check_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   3366\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate the input before fit and transform.\u001b[39;00m\n\u001b[0;32m   3367\u001b[0m \n\u001b[0;32m   3368\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3381\u001b[0m \u001b[38;5;124;03m        If True, check that n_features matches the length of self.lambdas_\u001b[39;00m\n\u001b[0;32m   3382\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3383\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_fit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3390\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3392\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m   3393\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll-NaN (slice|axis) encountered\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Shafiq\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Shafiq\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\utils\\validation.py:938\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 938\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    939\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    940\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    943\u001b[0m         )\n\u001b[0;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    949\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1.59174902e+00 2.51186153e+00 1.84644629e+00 1.57440230e+00\n 1.10209698e+00 2.07631859e+00 1.15103840e+00 4.44704883e+00\n 6.62982436e+00 9.67204202e-01 3.13779228e+00 1.50534822e+00\n 1.67886569e+00 5.19650831e+00 1.47370710e-01 1.82322058e-01\n 4.08511734e-02 3.57497536e+00 3.01156846e+00 4.08062856e+00\n 7.69044368e+00 3.21047912e+00 1.23785892e+00 3.03307195e+00\n 2.51748824e-01 2.04286377e+00 3.09459365e-01 5.78884090e+00\n 1.47565456e+00 1.07113144e+00 6.14560706e-01 2.97650968e+00\n 1.21816483e+00 1.68066941e+00 3.79371433e-02 1.92276186e+00\n 1.89399336e+00 1.91909595e+00 5.75583016e+00 2.29027792e+00\n 8.91036985e-01 1.14906482e+00 2.39221560e+00 1.24230592e-01\n 2.19782496e+00 2.22119487e+00 4.72413411e-01 2.76057375e-01\n 7.57923932e-01 9.04204113e-01 1.68885556e+00 1.15464862e+00\n 8.90899476e+00 2.15270225e-01 4.68603031e-01 3.51827107e-01\n 2.11748545e+00 5.84161070e-01 1.25588316e+00 5.60554027e-01\n 3.46254906e-01 2.33910824e-01 2.13614438e+00 2.97424543e-01\n 4.37761205e-01 9.20027931e-01 3.44066330e+00 2.04289773e-01\n 3.63963785e+00 2.02069566e-01 7.49806290e+00 1.26467321e+00\n 7.52385434e+00 1.85695700e+00 2.68849053e+00 7.99526050e-02\n 6.64820491e-01 2.56113523e-01 7.02352174e-01 2.52777283e-01\n 7.65401916e-01 1.06976877e+00 1.32594793e-01 2.35837905e+00\n 1.67219509e+00 6.16829680e-01 1.48151790e+00 1.97300627e-01\n 1.71579128e+00 5.29851185e+00 7.67120421e-01 2.20169184e+00\n 2.82661428e-01 2.51986766e+00 6.83308340e-01 4.04700874e-01\n 1.76625809e+00 4.06249087e-02 3.53148216e+00 9.41306914e-03\n 2.26526827e+00 6.29443334e-01 2.65751576e+00 6.55028637e+00\n 5.72041955e-01 1.71678593e+00 1.79318177e+00 1.69844164e+00\n 5.04839991e-01 6.10456341e+00 1.18524806e+00 3.74691984e+00\n 2.40447712e+00 7.06040264e-01 3.36184441e+00 1.01003750e+00\n 4.25899873e+00 1.74107164e+00 4.26966094e+00 2.35876586e+00\n 2.58381853e+00 1.39159892e+00 6.25093649e+00 2.06559404e+00\n 1.10279200e+00 1.86480575e+00 3.87595580e-02 7.17854433e-01\n 2.15864039e+00 6.85199242e-01 1.92475012e+00 1.11992215e+00\n 2.91147947e-01 7.08448259e-01 1.68777694e+00 1.78745815e+00\n 1.70815944e+00 2.11801880e+00 2.11169919e+00 1.12922101e+00\n 4.53726794e+00 9.16345763e-01 1.14492312e+00 4.44982926e+00\n 3.28179513e+00 2.43403898e+00 2.11225289e-01 5.03856428e+00\n 2.50521506e+00 1.35307875e+01 3.23740173e-01 4.05181759e+00\n 3.54651158e-01 1.91193283e+00 2.64367420e-01 3.76785780e+00\n 3.29343819e+00 1.68376190e+00 1.04574006e+00 1.43350780e-01\n 2.39087714e+00 1.20859815e+00 2.56066837e+00 4.02554547e+00\n 7.41992060e+00 3.87315447e+00 2.35664692e-02 8.92505658e-01\n 2.61859673e+00 3.76589950e-01 1.47226221e+00 1.11740111e-01\n 4.46278415e-01 3.73909415e-02 3.15682545e+00 5.07011424e-01\n 8.47314209e-01 5.26443775e+00 2.43759362e+00 6.47136209e-02\n 3.59914683e-01 1.94296429e+00 1.72184729e+00 5.43336158e-01\n 5.44269640e+00 1.90365943e+00 1.53415933e+00 1.78275715e+00\n 2.61957077e+00 7.47772992e-01 1.01573023e+00 4.71049134e-01\n 4.12064098e-01 5.77815124e+00 2.69069485e+00 1.34848917e+00\n 5.16025525e-01 5.87015301e-01 1.19561921e-01 1.13979512e+00\n 7.47339604e-01 2.38371623e+00 9.48832587e-01 3.95935471e-01\n 4.99767058e-02 1.39235344e-01 2.27507700e+00 1.20916246e+00\n 1.53823961e+00 4.53968009e+00 9.27930534e+00 4.88982053e-01\n 2.17580886e+00 6.11209800e-01 4.17344264e-02 2.84076693e+00\n 7.71375406e-01 9.67276785e-01 1.77500384e+00 3.55628665e+00\n 1.98300856e+00 4.12164245e+00 6.39149314e-01 3.19943892e+00\n 4.10695540e-01 6.10636929e+00 2.32622659e+00 4.85436986e-01\n 5.88896040e+00 2.62501602e+00 5.85902910e-01 4.79847045e-01\n 1.46045534e+00 5.19954998e-02 4.65050028e-01 1.10567675e+00\n 9.37352958e-01 1.24565863e+00 6.50432030e-01 1.76757132e+00\n 3.98807847e+00 2.50065176e-01 1.45704767e+00 2.83284062e-01\n 2.52362536e+00 1.00855986e+00 1.66675650e+00 4.04917519e-01\n 3.12951533e-01 1.33908117e+00 8.78910790e-01 5.64127169e+00\n 2.89910956e+00 2.76192615e+00 4.68098393e+00 1.74217168e-01\n 1.60678352e+00 1.75643014e+00 6.53699254e+00 6.91039156e-01\n 5.51055881e-01 2.11374343e-01 3.31321854e-02 5.30511699e+00\n 2.21681953e+00 3.07565745e+00 6.61819767e-01 1.76576107e+00\n 1.32184022e-01 1.32961551e+00 7.58804796e+00 4.18311319e+00\n 8.25459721e-01 6.51784179e+00 5.27154228e-01 5.96440138e+00\n 5.67328038e+00 3.21091755e+00 1.99092729e+00 4.14752287e+00\n 6.93506609e-01 3.78020341e+00 1.92402385e+00 2.66504916e-02\n 8.53071643e-01 3.20668191e-01 8.01589963e+00 1.30159469e+00\n 1.37588695e+00 2.04037418e+00 9.19582645e-01 2.94450069e-01\n 3.45326674e+00 4.21066572e-01 1.43209064e+00 5.08022770e-01\n 2.05936724e-01 3.96378073e+00 7.21788192e+00 6.47992612e+00\n 4.74077519e+00 2.97485948e+00 8.10365752e-01 1.69158978e-01\n 1.04593532e+00 5.28540930e-01 2.84251027e-01 1.09814754e-01\n 2.58629569e+00 2.29865075e-02 2.94440831e+00 3.17866368e-01\n 1.65724537e-01 1.87749097e-01 2.22977487e+00 5.63048037e-01\n 1.09131545e+00 1.63003668e+00 3.94011517e+00 2.59689126e+00\n 6.30320062e-01 2.81935777e-01 1.13933072e-01 7.17922638e-01\n 6.07943122e-01 1.21812892e+00 2.29948279e+00 2.37899250e+00\n 6.66806671e-01 9.55835990e-01 3.99711073e-01 3.10749098e+00\n 1.17055805e-01 2.38802674e+00 3.01643046e+00 3.00482562e+00\n 6.00650157e-01 9.36212901e-01 1.77152128e+00 6.37167711e-01\n 9.26780052e-01 4.38936328e-01 1.23183859e+00 9.12761072e-02\n 3.21683571e+00 1.60157718e-01 1.46309068e+00 7.32902581e-01\n 1.72333498e+00 6.40961751e+00 2.07449021e+00 7.20056586e-02\n 1.12565040e+00 1.42676856e+00 1.53650666e+00 2.28759075e+00\n 6.50341750e-01 2.75906459e-01 9.97384650e-01 6.26565879e+00\n 4.14370362e-01 4.68647993e+00 1.56967402e+00 1.22096569e+00\n 4.27484330e+00 1.22720844e+00 2.57592395e+00 1.01840496e+00\n 4.68773924e+00 2.34252739e+00 2.40542756e+00 7.94161912e-01\n 2.82756663e+00 2.02153832e+00 5.48927043e-01 3.49990097e-01\n 3.18311224e+00 6.39650996e+00 1.22549090e+00 1.78800282e+00\n 3.89995383e+00 1.22211512e+00 6.06788523e+00 1.71487023e+00\n 3.43813863e+00 4.79035973e+00 3.38046985e+00 3.47313125e-01\n 1.98255901e+00 1.01643891e+00 1.29531392e-01 1.10340723e+00\n 5.98656768e-01 3.78145835e+00 6.77437109e-02 6.38752377e+00\n 8.78153968e-01 8.82309623e-01 3.29265637e-02 4.09704536e-01\n 1.02585400e+00 5.29837663e+00 2.09865504e-01 5.81183921e+00\n 4.07258834e+00 1.21086756e+00 7.91131186e-01 5.29869868e-01\n 1.90624508e+00 6.72678470e-02 3.14582421e-02 1.12001676e+00\n 1.41003892e-01 5.80546823e-01 4.99901642e-01 5.83892151e-01\n 2.80951426e-01 2.42184895e-02 2.45430024e-01 1.92718537e+00\n 7.31912391e+00 9.28055905e+00 1.05206160e+00 3.55753522e-01\n 2.03643517e+00 1.34788690e+00 9.09564818e+00 1.35068316e-01\n 3.05787774e+00 6.80474423e-01 5.52610391e-01 2.17240663e+00\n 5.64893428e-01 2.19238514e+00 1.45675516e+00 1.10360425e+00\n 1.61795938e+00 6.76692238e-01 2.45226442e+00 1.07179759e+00\n 8.94279809e-01 3.52817477e+00 5.17965218e+00 9.41985419e-02\n 5.29564552e-01 8.57015227e-01 3.37443656e+00 8.46603121e+00\n 6.94571148e+00 4.70666961e+00 7.03534769e-01 9.65944031e+00\n 5.73818185e-01 2.23889074e-01 6.02993665e+00 5.31633098e-01\n 2.34087146e+00 1.20256753e-01 2.62392614e+00 4.26940476e+00\n 6.36109084e-01 9.53031643e-01 9.37756312e-01 2.76291820e+00\n 5.43111585e-01 3.77129447e-01 1.19309984e+00 7.26157689e-01\n 3.65505255e+00 5.42939939e-01 1.39587510e+00 5.71485059e+00\n 2.01023131e+00 4.03916901e+00 5.63382332e+00 2.77871700e+00\n 2.40511468e+00 6.88188782e+00 1.03702594e+01 1.20230930e+00\n 1.47012752e-01 6.92866656e-01 3.30586031e-01 1.08080541e+00\n 2.81490307e-01 1.85327719e+00 9.65150432e-01 4.51495357e+00\n 6.87124674e+00 1.58321821e+00 6.42680604e-01 1.79410603e+00\n 4.54142025e+00 1.04422262e+00 1.60627357e+00 6.33954754e-01\n 1.21556954e+00 1.02737120e+00 5.71137854e-01 1.40989864e+00\n 7.43231511e-01 9.33728688e-01 1.48875650e+00 2.77735458e+00\n 8.11452682e-01 5.15822632e+00 3.96562514e+00 9.98312160e-02\n 5.85101207e-01 1.18167046e+00 2.21031761e-01 8.56882056e-01\n 2.69489763e+00 2.28208666e+00 1.94775722e+00 2.47939619e+00\n 4.58634355e-01 8.36183322e-01 2.25552089e+00 4.22781362e+00\n 1.56911339e+00 6.64521258e-01 6.14035419e-02 2.47807302e+00\n 1.58306948e-02 9.32594038e-01 1.51233250e+00 5.10495294e+00\n 1.87510777e-01 1.04155773e+00 4.92272908e-02 8.38958653e-01\n 1.94694507e+00 6.54420776e-01 4.70811728e-01 2.45925128e-01\n 1.72142940e+00 2.37665832e+00 2.22922202e+00 5.94641654e+00\n 5.41374835e-03 2.08368894e+00 1.83454361e+00 1.77705743e+00\n 6.58129796e+00 3.40312429e-02 2.38463156e+00 3.36056481e+00\n 1.42591298e+00 8.12825723e-01 3.12931310e+00 2.04603565e-01\n 1.16692037e+00 1.46773992e+00 2.36805548e+00 1.90568971e-01\n 5.16918502e-01 1.05628799e+00 1.95258405e+00 4.36004090e+00\n 1.92899951e+00 2.86497411e-01 7.88291731e+00 4.10810493e+00\n 1.39720712e+00 5.11103548e+00 1.55907006e+00 5.13586537e+00\n 3.54270662e+00 6.90201999e+00 5.04603492e+00 7.33981306e-02\n 3.84191144e-01 9.85757530e-01 6.07906311e+00 7.13432517e-01\n 3.49820522e-01 4.34846584e+00 1.18260557e+00 4.76923076e+00\n 3.49255579e-01 2.16420375e+00 1.16057919e+00 1.59140305e-01\n 2.38450448e+00 5.68439495e-01 8.08431548e-02 1.23632297e-01\n 1.26046885e-01 4.76613654e+00 2.69325456e+00 4.56678800e+00\n 2.23303718e+00 1.50553931e+00 7.26094305e-01 1.23918193e+01\n 8.99426740e-01 1.27220691e+00 9.50418872e-01 7.77728977e+00\n 3.83915800e-01 7.94958166e-01 2.28104892e+00 1.30587198e-01\n 1.86916082e+00 1.29882145e+00 6.68150159e-01 5.44702468e-01\n 1.44520448e+00 9.17502607e-01 1.21952434e+00 8.23401162e-01\n 7.04630252e+00 2.86446545e-01 2.03631286e-01 8.41335354e-01\n 1.78821179e+00 2.15278090e+00 1.01252791e+00 1.44669540e+01\n 8.67398934e-01 2.55600430e+00 2.02991791e+00 3.35386948e+00\n 7.47829715e+00 4.41080164e+00 2.89261512e+00 2.39630275e+00\n 8.17435293e-01 3.19599561e-01 1.29367203e-01 5.53884448e-01\n 1.13225910e+00 1.47627350e+00 2.96634682e+00 6.37576829e+00\n 2.49586178e-01 2.26346669e-01 1.78170764e+00 2.73610806e+00\n 3.76972918e+00 5.49250377e+00 8.19986939e+00 1.02099033e+00\n 9.57153131e-01 3.19888439e-01 2.30994906e+00 2.13866215e+00\n 3.96191058e+00 2.04636950e-01 1.37742170e+00 1.74015983e+00\n 5.52975368e-01 3.70312115e-01 3.92624661e+00 1.20636047e-01\n 1.27210095e+00 2.46220905e-01 1.22150836e+00 7.82028219e+00\n 1.10227589e+00 3.89156916e+00 2.49575039e-01 6.32854782e-01\n 1.03433384e+00 1.02102515e+00 2.22572759e+00 8.45379592e-01\n 2.50189731e+00 2.03879036e+00 1.01885702e+00 1.13042328e+00\n 1.90657189e+00 1.45232119e-01 3.45651878e+00 2.11928991e+00\n 2.59175565e+00 1.53972387e+00 2.34140080e-01 1.03850746e+00\n 1.03964388e+00 7.74394934e-01 6.08159947e-02 2.67313683e+00\n 2.32583327e-01 1.86437348e+00 2.42951144e+00 2.01454536e+00\n 6.39531761e+00 2.18063727e-01 4.03732755e+00 5.92494926e-02\n 1.53107817e+00 1.03584690e+00 1.48544752e+00 9.08575158e-01\n 4.22842343e-01 3.86162100e-02 1.46024406e+00 3.70017845e+00\n 9.34306449e-01 5.04279355e-01 1.67920082e-01 1.78342156e-01\n 5.00506559e-01 2.10752278e-01 6.15877585e-01 1.36877754e-01\n 1.35711752e-01 3.87972347e+00 3.53761396e-01 1.64051801e+00\n 2.96962816e+00 1.21911839e+00 3.32980380e-01 4.45277713e-01\n 1.13473624e+00 1.50254474e+00 8.59844395e-01 3.04175181e+00\n 2.78077866e+00 5.24040305e+00 5.87598875e-02 4.52080085e+00\n 9.97032684e-01 4.21358429e+00 2.34743545e+00 8.73999963e+00\n 2.84826206e+00 9.06826825e-01 1.39055158e+00 9.44457503e-01\n 9.07982898e-01 6.04656274e-01 1.37024015e+00 2.28977290e+00\n 6.49633611e-01 1.48627133e+00 2.49721711e-01 3.48338444e-01\n 9.58744010e-02 7.06248294e+00 7.73564380e-03 3.93441380e-01\n 1.89797268e+00 1.69742825e-01 4.27238789e+00 2.54322003e+00\n 6.78586157e+00 1.41707216e+00 7.14503601e-01 1.59479695e+00\n 5.34204987e+00 1.47111352e+00 6.21784123e-01 4.19763676e+00\n 9.30171479e-01 2.76861542e-03 5.69200379e-01 7.66136137e-01\n 3.91483679e+00 1.22683612e+00 1.17608763e+00 8.19254314e-01\n 4.25186118e+00 5.80181813e+00 9.62939600e+00 9.45587089e-01\n 6.77148164e+00 3.13927675e+00 2.25210560e+00 5.61782311e-01\n 4.87859340e-01 3.63158444e-01 5.12158787e+00 6.96497269e-01\n 1.20695757e+00 1.36227056e+00 3.01170230e+00 3.71881314e+00\n 2.99490432e-01 1.11340533e+00 3.70117124e+00 3.40786321e+00\n 2.16092145e-01 3.40114185e-01 7.25382272e-01 1.56699599e-01\n 1.10559866e+00 2.27721313e-01 1.67966701e+00 5.66203662e-01\n 1.81482584e+00 2.50051095e-01 7.44974860e+00 5.39306963e+00\n 9.94492940e-01 5.54615067e-01 5.76426328e-01 1.32094777e+00\n 8.16289931e-02 2.04166487e+00 1.04952089e+00 9.47723155e-01\n 3.31478905e+00 2.46910775e+00 6.17279440e+00 8.67532386e-01\n 4.55661957e+00 2.93906662e+00 8.84542391e-01 1.94395277e+00\n 6.80956381e-01 4.14930473e+00 2.38529730e-01 4.77617122e-01\n 4.04313868e-01 1.03176344e+00 2.73481144e+00 1.49692848e+00\n 1.33759735e+00 1.09222798e-03 1.10816827e+00 1.31326360e-01\n 4.67027402e-01 5.38811528e+00 4.85157913e-01 3.90861758e+00\n 3.24802087e+00 3.46675037e-01 1.86134713e+00 2.45831583e-01\n 2.60308423e+00 2.02925350e+00 3.34197314e+00 1.30548722e+00\n 4.92698917e+00 1.01216420e-01 6.93134018e-01 2.51090134e+00\n 1.08294500e+00 3.79783528e-01 2.26809446e-01 3.40024783e+00\n 1.28165215e+00 4.27895510e+00 2.64318021e+00 1.05433758e+00\n 9.35248171e-01 1.44984687e+00 4.39753068e+00 2.67332209e+00\n 1.03325732e-02 2.36937233e+00 5.03918022e+00 2.47889435e+00\n 3.89612207e-01 1.32143018e+00 3.02380840e-01 8.89436912e-01\n 5.53296018e+00 5.13584554e+00 6.64903844e-01 8.29913152e-01\n 1.83364609e+00 6.60436788e+00 3.19871207e-01 5.93894103e-01\n 4.13592460e+00 1.35412342e+00 4.58449922e+00 4.10405650e-01\n 1.52143322e+00 7.89850593e-01 7.61181785e-01 1.18434963e+00\n 1.13506516e+00 8.84300342e-01 4.92952041e+00 2.63162844e+00\n 2.60057825e+00 6.84736829e-01 1.72412327e+00 3.02080965e+00\n 3.17525860e+00 8.44806893e-01 2.94695556e+00 2.66280870e+00\n 3.05152307e-01 4.01901722e+00 1.16436210e+00 1.33266174e+00\n 1.18975252e+00 1.67794655e+00 1.94133147e+00 1.37902585e+00\n 4.03163503e+00 1.97629732e+00 1.02641675e+00 1.07807903e+00\n 3.33030948e+00 8.56010302e-01 4.75131090e-01 1.22438872e-01\n 4.17538050e+00 5.01544475e+00 2.55939903e-01 8.14354370e-01\n 3.85645975e-01 2.46366737e-01 4.60250682e+00 1.17117690e-01\n 7.87321175e+00 2.02849565e-01 3.98243133e+00 1.67175514e+00\n 9.17470672e-01 8.38141625e-01 2.83238698e+00 7.55427415e-01\n 2.14191010e+00 1.45682795e+00 1.32704334e+00 4.62854972e+00\n 1.61776739e+00 3.50732804e+00 2.58614388e+00 7.86405080e-02\n 2.96658038e+00 4.88913776e-01 4.66917649e+00 8.77453500e-02\n 8.10146473e-01 2.10127669e-01 1.29095955e+00 3.42984616e+00\n 7.08177609e-01 3.27238828e-01 8.01752414e-01 3.36272883e+00\n 3.02538904e-01 5.15890453e-01 1.42674015e-01 2.44637951e+00\n 1.00582484e+00 7.44563562e-01 2.53614384e+00 8.18878617e-01\n 2.60222532e+00 3.37695570e+00 4.90938970e-01 7.28541949e+00\n 3.54328830e-01 6.87350773e-01 3.96402649e-01 8.47784672e-01\n 1.30808713e+00 1.47702508e+00 3.84290790e+00 4.40453691e+00\n 4.97189046e-01 1.95045810e+00 2.36432388e-01 1.22856058e+00\n 7.78200112e-01 7.61059427e-01 1.31781711e+00 2.61739027e+00\n 1.43384435e-01 4.22679661e+00 2.65464593e+00 3.88381975e-01\n 5.59904551e+00 1.41170399e+00 1.71220615e+01 4.39447497e-01\n 1.53104094e+00 6.85679451e-01 7.25310028e-01 1.78839998e+00\n 5.09490243e+00 3.27221948e+00 2.57428422e+00 1.63820909e+00\n 5.10976153e+00 1.35597103e+00 4.14028468e+00 3.59131384e+00\n 4.81178052e-01 2.95003663e+00 2.44916640e-02 7.79664494e-01\n 5.21606323e-01 1.41393634e+00 2.67008616e+00 2.05564058e-01\n 1.44689199e+00 5.57457717e+00 5.19217162e-01 2.26108006e+00].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt_boxcox = PowerTransformer(method='box-cox')\n",
    "#pt_yeojohnson = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "# data must be postive for box-cox\n",
    "df['Box_cox'] = pt_boxcox.fit_transform(df['values'])\n",
    "#df['Yeo_johnson'] = pt_yeojohnson.fit_transform(df['values']) \n",
    "\n",
    "df.head()\n",
    "# df['values'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## draw histogram\n",
    "sns.histplot(df['Box_cox'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 and L1 normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling vs Normalization\n",
    "\n",
    "can be used for same purpose mostly in ML \n",
    "\n",
    "Scaling: some algrathm sensitive to scale of data\n",
    "\n",
    "Normalization: when data is not normal distributed\n",
    "\n",
    "Receive data from user\n",
    "transform or scale it for processing\n",
    "Inverse to normal when back data to user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
